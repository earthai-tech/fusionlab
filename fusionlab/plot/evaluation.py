# -*- coding: utf_8 -*-
# License: BSD-3-Clause
# Author: LKouadio <etanoyau@gmail.com>

"""
Plotting utilities for evaluating forecasting models.
"""
import warnings
from typing import ( 
    List, 
    Tuple, 
    Optional, 
    Union, 
    Any, 
    Callable
)
from sklearn.metrics import (
    mean_absolute_error,
    mean_squared_error,
    mean_absolute_percentage_error
)

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.colors as mcolors

from ..decorators import isdf 
from ..utils.generic_utils import vlog
from ..metrics import coverage_score


__all__ = [
    'plot_metric_radar', 'plot_forecast_comparison', 
    'plot_metric_over_horizon' 
    ]

@isdf 
def plot_metric_radar(
    forecast_df: pd.DataFrame,
    segment_col: str,
    metric: Union[str, Callable] = 'mae',
    target_name: str = "target",
    quantiles: Optional[List[float]] = None,
    output_dim: int = 1,
    actual_col_pattern: str = "{target_name}_actual",
    pred_col_pattern_point: str = "{target_name}_pred",
    pred_col_pattern_quantile: str = "{target_name}_q{quantile_int}",
    aggregate_across_horizon: bool = True,
    scaler: Optional[Any] = None,
    scaler_feature_names: Optional[List[str]] = None,
    target_idx_in_scaler: Optional[int] = None,
    figsize: Tuple[float, float] = (8, 8),
    max_segments_to_plot: Optional[int] = 12,
    verbose: int = 0,
    **plot_kwargs: Any
    ) -> None:
    """
    Visualizes a performance metric across different segments using a radar chart.
    
    This function calculates a specified performance metric for each unique
    value (segment) in a given column of the `forecast_df` and
    displays these values on a radar chart. Each axis of the radar
    corresponds to a segment. It supports point and quantile forecasts
    (using the median for metric calculation if quantiles are present).
    
    The input `forecast_df` is expected to be in a long format, typically
    generated by :func:`~fusionlab.nn.utils.format_predictions_to_dataframe`.
    
    Parameters
    ----------
    forecast_df : pd.DataFrame
        A pandas DataFrame containing the forecast data in long format.
        Must include 'sample_idx', 'forecast_step', prediction columns,
        the `segment_col`, and actual value columns (e.g.,
        '{target_name}_actual').
    segment_col : str
        The name of the column in `forecast_df` whose unique values
        will define the axes (segments) of the radar chart (e.g.,
        'ItemID', 'Month', 'DayOfWeek').
    metric : str or Callable, default 'mae'
        The performance metric to calculate and plot for each segment.
        - Supported string names: 'mae', 'mse', 'rmse', 'mape', 'smape'.
        - Custom metric: A callable that accepts `(y_true, y_pred)`
          and returns a scalar score. If `quantiles` are used, `y_pred`
          passed to the custom metric will be the median prediction.
    target_name : str, default "target"
        The base name of the target variable, used to find relevant
        prediction and actual columns.
    quantiles : List[float], optional
        List of quantiles predicted (e.g., `[0.1, 0.5, 0.9]`). If provided,
        and a generic metric like 'mae' is used, the median (0.5 or
        closest) quantile prediction will be used as `y_pred`.
        Default is ``None`` (point forecast).
    output_dim : int, default 1
        The number of target variables predicted. If > 1, separate
        radar charts will be generated for each output dimension.
    actual_col_pattern : str, default "{target_name}_actual"
        Format string to identify actual value columns.
        Placeholders: `{target_name}`, `{o_idx}` (if output_dim > 1).
    pred_col_pattern_point : str, default "{target_name}_pred"
        Format string for point prediction columns.
    pred_col_pattern_quantile : str, default "{target_name}_q{quantile_int}"
        Format string for quantile prediction columns.
        Placeholders: `{target_name}`, `{o_idx}`, `{quantile_int}`.
    aggregate_across_horizon : bool, default True
        If ``True``, the metric for each segment is calculated by
        aggregating errors/predictions over all `forecast_step` values
        within that segment. If ``False``, this function would expect
        `forecast_df` to potentially contain pre-calculated metrics
        per step (this mode is less common for radar plots of overall
        segment performance).
    scaler : Any, optional
        Fitted scikit-learn-like scaler for inverse transforming data
        before metric calculation. Default is ``None``.
    scaler_feature_names : List[str], optional
        List of all feature names the `scaler` was fit on. Required
        if `scaler` is provided.
    target_idx_in_scaler : int, optional
        Index of `target_name` within `scaler_feature_names`. Required
        if `scaler` is provided.
    figsize : Tuple[float, float], default (8, 8)
        Figure size `(width, height)` in inches for each radar chart.
    max_segments_to_plot : int, optional
        Maximum number of segments (axes) to display on a single radar
        chart. If the number of unique segments in `segment_col` exceeds
        this, a warning is issued, and only the top N (by count or first N)
        might be plotted, or the plot might become cluttered.
        Default is 12.
    verbose : int, default 0
        Verbosity level for logging.
    **plot_kwargs : Any
        Additional keyword arguments passed to the Matplotlib
        `ax.plot()` and `ax.fill()` calls for the radar chart lines
        and fill (e.g., `color`, `linewidth`, `alpha`).
    
    Returns
    -------
    None
        This function generates and shows plots using Matplotlib.
    
    Raises
    ------
    ValueError
        If `forecast_df` is missing required columns, or if
        `segment_col` is not found.
        If `metric` is an unsupported string or invalid callable.
        If `quantiles` are required for a metric but not provided.
    TypeError
        If `forecast_df` is not a pandas DataFrame.
    
    See Also
    --------
    fusionlab.nn.utils.format_predictions_to_dataframe :
        Utility to generate the `forecast_df`.
    fusionlab.plot.evaluation.plot_metric_over_horizon :
        Visualizes metrics across forecast steps.
    
    Examples
    --------
    >>> from fusionlab.nn.utils import format_predictions_to_dataframe
    >>> from fusionlab.plot.evaluation import plot_metric_radar # Assuming new location
    >>> import pandas as pd
    >>> import numpy as np
    
    >>> # Assume preds_point (B,H,O) and y_true_seq (B,H,O) are available
    >>> B, H, O = 20, 3, 1
    >>> preds = np.random.rand(B, H, O)
    >>> y_true = np.random.rand(B, H, O) + preds * 0.5
    >>> df = format_predictions_to_dataframe(
    ...     predictions=preds, y_true_sequences=y_true,
    ...     target_name="sales", forecast_horizon=H, output_dim=O
    ... )
    >>> # Add a categorical segment column
    >>> df['item_category'] = np.random.choice(['A', 'B', 'C', 'D'], size=len(df))
    
    >>> # Example 1: Plot MAE by item_category
    >>> # plot_metric_radar(df, segment_col='item_category',
    ... #                   metric='mae', target_name="sales")
    
    >>> # Example 2: Quantile forecast, plot MAE of median by month
    >>> # df_quant = format_predictions_to_dataframe(...)
    >>> # df_quant['month_of_forecast'] = (df_quant['forecast_step'] % 12) + 1
    >>> # plot_metric_radar(df_quant, segment_col='month_of_forecast',
    ... #                   metric='mae', target_name="sales",
    ... #                   quantiles=[0.1, 0.5, 0.9])
    """

    vlog(f"Starting metric radar plot for segment '{segment_col}'...",
         level=3, verbose=verbose)

    if not isinstance(forecast_df, pd.DataFrame):
        raise TypeError("`forecast_df` must be a pandas DataFrame.")
    if segment_col not in forecast_df.columns:
        raise ValueError(
            f"Segment column '{segment_col}' not found in forecast_df."
            )
    if 'forecast_step' not in forecast_df.columns and \
       not aggregate_across_horizon:
        # If not aggregating, forecast_step is needed for per-step metrics
        # This function's current design implies aggregation for radar.
        pass

    df_eval = forecast_df.copy()

    # --- Inverse Transform Data if Scaler Provided ---
    if scaler is not None:
        # ... (Inverse transform logic as in plot_metric_over_horizon) ...
        if scaler_feature_names is None or target_idx_in_scaler is None:
            warnings.warn(
                "Scaler provided, but `scaler_feature_names` or "
                "`target_idx_in_scaler` is missing. Metrics calculated "
                "on potentially scaled data.", UserWarning
            )
        else:
            vlog("  Applying inverse transformation for metric calculation...",
                 level=4, verbose=verbose)
            cols_to_inv = [] # Collect relevant pred/actual columns
            for o_idx in range(output_dim):
                act_col = actual_col_pattern.format(target_name=target_name, o_idx=o_idx)
                if act_col in df_eval.columns: cols_to_inv.append(act_col)
                if quantiles:
                    for q_val in quantiles:
                        q_int = int(q_val * 100)
                        pred_col = pred_col_pattern_quantile.format(
                            target_name=target_name, o_idx=o_idx, quantile_int=q_int)
                        if pred_col in df_eval.columns: cols_to_inv.append(pred_col)
                else:
                    pred_col = pred_col_pattern_point.format(target_name=target_name, o_idx=o_idx)
                    if pred_col in df_eval.columns: cols_to_inv.append(pred_col)
            
            dummy_shape = (len(df_eval), len(scaler_feature_names))
            for col_name in cols_to_inv:
                if col_name in df_eval.columns:
                    try:
                        dummy_arr = np.zeros(dummy_shape)
                        dummy_arr[:, target_idx_in_scaler] = df_eval[col_name]
                        df_eval[col_name] = scaler.inverse_transform(
                            dummy_arr)[:, target_idx_in_scaler]
                    except Exception as e:
                        warnings.warn(f"Failed to inverse transform '{col_name}'. Error: {e}")
            vlog("    Inverse transformation applied.", level=5, verbose=verbose)


    # --- Prepare Metric Calculation ---
    metric_callable: Optional[Callable] = None
    metric_name_str = ""
    if isinstance(metric, str):

        if metric_name_str == 'mae':
            metric_callable = mean_absolute_error
        elif metric_name_str == 'mse':
            metric_callable = mean_squared_error
        elif metric_name_str == 'rmse':
            metric_callable = lambda yt, yp: np.sqrt(mean_squared_error(yt, yp))
        elif metric_name_str == 'mape':
            metric_callable = mean_absolute_percentage_error
        elif metric_name_str == 'smape':
            metric_callable = _calculate_smape_radar
        # Coverage and Pinball are more complex for per-segment radar
        # as they require specific quantile columns.
        # For simplicity, this radar plot will use MAE/MSE on median if quantiles.
        else:
            raise ValueError(
                f"Unsupported metric string: '{metric_name_str}'. "
                "Choose from 'mae', 'mse', 'rmse', 'mape', 'smape' "
                "or provide a custom callable."
            )
            
    elif callable(metric):
        metric_callable = metric
        metric_name_str = getattr(metric, '__name__', 'custom_metric')
    else:
        raise TypeError("`metric` must be a string or a callable function.")

    # --- Loop through each output dimension to create separate radar plots ---
    for o_idx_plot in range(output_dim):
        vlog(f"  Processing radar for output dimension: {o_idx_plot}",
             level=4, verbose=verbose)

        # Determine actual and prediction columns for this output dimension
        actual_col = actual_col_pattern.format(
            target_name=target_name, o_idx=o_idx_plot
            )
        if actual_col not in df_eval.columns:
            warnings.warn(
                f"Actual column '{actual_col}' not found for output "
                f"dimension {o_idx_plot}. Skipping radar for this dimension.",
                UserWarning
            )
            continue

        pred_col_for_metric = ""
        if quantiles: # Use median for standard metrics if quantiles present
            median_q_val = 0.5
            if 0.5 not in quantiles:
                median_q_val = sorted(quantiles)[len(quantiles) // 2]
                vlog(f"    0.5 quantile not found for metric '{metric_name_str}'. "
                     f"Using q={median_q_val} as median.", level=2, verbose=verbose)
            pred_col_for_metric = pred_col_pattern_quantile.format(
                target_name=target_name, o_idx=o_idx_plot,
                quantile_int=int(median_q_val * 100)
            )
        else: # Point forecast
            pred_col_for_metric = pred_col_pattern_point.format(
                target_name=target_name, o_idx=o_idx_plot
            )

        if pred_col_for_metric not in df_eval.columns:
            warnings.warn(
                f"Prediction column '{pred_col_for_metric}' not found for "
                f"output_dim {o_idx_plot}. Skipping radar for this dimension.",
                UserWarning
            )
            continue

        # --- Calculate Metric per Segment ---
        # If not aggregating, data should already be one row per segment
        # (and potentially per forecast_step). This function assumes aggregation.
        if not aggregate_across_horizon:
            warnings.warn(
                "`aggregate_across_horizon=False` is not fully supported "
                "for radar plot in this version. Metric will be calculated "
                "by aggregating over all available forecast_steps per segment.",
                UserWarning
            )

        segment_metrics = {}
        grouped_by_segment = df_eval.groupby(segment_col)

        for segment_val, group_df in grouped_by_segment:
            y_true_segment = group_df[actual_col].values
            y_pred_segment = group_df[pred_col_for_metric].values

            if len(y_true_segment) > 0 and len(y_pred_segment) > 0:
                try:
                    metric_value = metric_callable(y_true_segment, y_pred_segment)
                    segment_metrics[str(segment_val)] = metric_value
                except Exception as e:
                    warnings.warn(
                        f"Error calculating metric '{metric_name_str}' for "
                        f"segment '{segment_val}', output_dim {o_idx_plot}: {e}",
                        UserWarning
                    )
            else:
                 vlog(f"    Skipping segment '{segment_val}' for output_dim "
                      f"{o_idx_plot} due to insufficient data.",
                      level=5, verbose=verbose)


        if not segment_metrics:
            vlog(f"  No metric values calculated for output_dim {o_idx_plot}. "
                 "Skipping radar plot.", level=2, verbose=verbose)
            continue

        labels = list(segment_metrics.keys())
        values = list(segment_metrics.values())

        if max_segments_to_plot and len(labels) > max_segments_to_plot:
            warnings.warn(
                f"Number of segments ({len(labels)}) exceeds "
                f"`max_segments_to_plot` ({max_segments_to_plot}). "
                f"Plot may be cluttered or truncated (not implemented yet)."
                # For now, plots all, but warns.
            )
            # Truncation logic could be added here if desired
            # labels = labels[:max_segments_to_plot]
            # values = values[:max_segments_to_plot]

        num_vars = len(labels)
        if num_vars < 3: # Radar plots need at least 3 axes to look right
            vlog(f"  Need at least 3 segments for a meaningful radar plot, "
                 f"got {num_vars} for output_dim {o_idx_plot}. Skipping.",
                 level=2, verbose=verbose)
            continue

        # --- Create Radar Plot ---
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        values += values[:1] # Close the plot
        angles += angles[:1]

        fig, ax = plt.subplots(figsize=figsize, subplot_kw=dict(polar=True))
        ax.plot(angles, values,
                color=plot_kwargs.get('color', 'blue'),
                linewidth=plot_kwargs.get('linewidth', 2),
                linestyle=plot_kwargs.get('linestyle', 'solid'),
                label=metric_name_str.upper()
                )
        ax.fill(angles, values,
                color=plot_kwargs.get('fill_color', 'skyblue'),
                alpha=plot_kwargs.get('alpha', 0.25)
                )

        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(labels)
        ax.set_yticks(np.linspace(min(values), max(values), 5)) # Example y-ticks
        # ax.set_yticklabels([f"{y:.2f}" for y in ax.get_yticks()]) # Format y-ticks

        plot_title_radar = f"{metric_name_str.upper()} by {segment_col}"
        if output_dim > 1:
            plot_title_radar += f" (Output Dim {o_idx_plot})"
        ax.set_title(plot_title_radar, va='bottom', fontsize=14)
        # ax.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1)) # Optional legend

        plt.tight_layout()
        plt.show()

    vlog("Metric radar plot generation complete.", 
         level=3, verbose=verbose)
    
    return ax 

@isdf 
def plot_forecast_comparison(
    forecast_df: pd.DataFrame,
    target_name: str = "target",
    quantiles: Optional[List[float]] = None,
    output_dim: int = 1,
    kind: str = "temporal",
    actual_data: Optional[pd.DataFrame] = None, # For future use
    dt_col: Optional[str] = None, # For x-axis if not 'forecast_step'
    actual_target_name: Optional[str] = None,
    sample_ids: Optional[Union[int, List[int], str]] = "first_n",
    num_samples: int = 3,
    horizon_steps: Optional[Union[int, List[int], str]] = 1,
    spatial_cols: Optional[List[str]] = None,
    max_cols: int = 2,
    figsize_per_subplot: Tuple[float, float] = (7, 4),
    scaler: Optional[Any] = None,
    scaler_feature_names: Optional[List[str]] = None,
    target_idx_in_scaler: Optional[int] = None,
    titles: Optional[List[str]] = None,
    verbose: int = 0,
    **plot_kwargs: Any
) -> None:
    """
    Visualizes model forecasts from a structured DataFrame.

    (Full NumPy docstring omitted for brevity as requested.
    It would detail all parameters, their interactions, expected
    DataFrame structure, and various plotting scenarios, similar to
    the one in artifact `plot_forecasts_docstring`.)
    """
    vlog(f"Starting forecast visualization (kind='{kind}')...",
         level=3, verbose=verbose)

    if not isinstance(forecast_df, pd.DataFrame):
        raise TypeError(
            "`forecast_df` must be a pandas DataFrame, typically "
            "the output of `format_predictions_to_dataframe`."
            )

    if 'sample_idx' not in forecast_df.columns or \
       'forecast_step' not in forecast_df.columns:
        raise ValueError(
            "`forecast_df` must contain 'sample_idx' and "
            "'forecast_step' columns."
            )

    # --- Data Preparation & Inverse Transform ---
    df_to_plot = forecast_df.copy() # Work on a copy
    actual_col_names_in_df: List[str] = []
    pred_col_names_in_df: List[str] = []

    # Identify prediction and actual columns
    base_pred_name = target_name
    base_actual_name = actual_target_name if actual_target_name \
        else target_name

    # Determine sorted quantiles if provided
    sorted_quantiles_list: Optional[List[float]] = None
    if quantiles:
        try:
            sorted_quantiles_list = sorted([float(q) for q in quantiles])
            if not all(0 < q < 1 for q in sorted_quantiles_list):
                raise ValueError("Quantiles must be between 0 and 1.")
        except Exception as e:
            raise ValueError(f"Invalid `quantiles` provided: {e}") from e

    # Construct column names based on output_dim and quantiles
    for o_idx in range(output_dim):
        current_base_pred = base_pred_name
        current_base_actual = base_actual_name
        if output_dim > 1:
            current_base_pred += f"_{o_idx}"
            current_base_actual += f"_{o_idx}"

        actual_col = f"{current_base_actual}_actual"
        if actual_col in df_to_plot.columns:
            actual_col_names_in_df.append(actual_col)

        if sorted_quantiles_list:
            for q_val in sorted_quantiles_list:
                q_suffix = f"_q{int(q_val*100)}"
                col_name = f"{current_base_pred}{q_suffix}"
                if col_name in df_to_plot.columns:
                    pred_col_names_in_df.append(col_name)
        else: # Point forecast
            col_name = f"{current_base_pred}_pred"
            if col_name in df_to_plot.columns:
                pred_col_names_in_df.append(col_name)

    if not pred_col_names_in_df:
        warnings.warn(
            "No prediction columns found in `forecast_df` based on "
            "`target_name` and `quantiles`. Plotting may be limited."
            )
    if actual_data is None and not actual_col_names_in_df:
        vlog("  No actual data columns found in `forecast_df` and "
             "`actual_data` not provided. Plotting predictions only.",
             level=2, verbose=verbose)

    # Apply inverse transform if scaler is provided
    if scaler is not None:
        # ... (Inverse transform logic as in previous artifact
        #      `visualize_forecasts_util`, using `df_to_plot`,
        #      `pred_col_names_in_df`, `actual_col_names_in_df`) ...
        if scaler_feature_names is None or target_idx_in_scaler is None:
            warnings.warn(
                "Scaler provided, but `scaler_feature_names` or "
                "`target_idx_in_scaler` is missing. Inverse transform "
                "cannot be applied correctly to specific target columns.",
                UserWarning
            )
        else:
            vlog("  Applying inverse transformation using scaler...",
                 level=4, verbose=verbose)
            cols_to_inv = pred_col_names_in_df + actual_col_names_in_df
            dummy_shape = (len(df_to_plot), len(scaler_feature_names))

            for col_name in cols_to_inv:
                if col_name in df_to_plot.columns:
                    try:
                        dummy_arr = np.zeros(dummy_shape)
                        dummy_arr[:, target_idx_in_scaler] = df_to_plot[col_name]
                        df_to_plot[col_name] = scaler.inverse_transform(
                            dummy_arr
                            )[:, target_idx_in_scaler]
                    except Exception as e:
                        warnings.warn(
                            f"Failed to inverse transform column '{col_name}'. "
                            f"Plotting scaled value. Error: {e}"
                            )
            vlog("    Inverse transformation applied.", level=5, verbose=verbose)

    # --- Select Samples/Items to Plot ---
    unique_sample_ids = df_to_plot['sample_idx'].unique()
    selected_ids_for_plot: Union[np.ndarray, List] = np.array([]) # Ensure array type

    if isinstance(sample_ids, str):
        if sample_ids.lower() == "all":
            selected_ids_for_plot = unique_sample_ids
        elif sample_ids.lower() == "first_n":
            selected_ids_for_plot = unique_sample_ids[:num_samples]
        else:
            warnings.warn(f"Unknown string for `sample_ids`: "
                          f"'{sample_ids}'. Plotting first sample.")
            if len(unique_sample_ids) > 0:
                selected_ids_for_plot = unique_sample_ids[:1]
    elif isinstance(sample_ids, int):
        if 0 <= sample_ids < len(unique_sample_ids):
            selected_ids_for_plot = [unique_sample_ids[sample_ids]]
        else:
            warnings.warn(f"sample_idx {sample_ids} out of range. "
                          "Plotting first sample.")
            if len(unique_sample_ids) > 0:
                selected_ids_for_plot = unique_sample_ids[:1]
    elif isinstance(sample_ids, list):
        selected_ids_for_plot = [
            sid for sid in sample_ids if sid in unique_sample_ids
            ]
    if not isinstance(selected_ids_for_plot, np.ndarray):
        selected_ids_for_plot = np.array(selected_ids_for_plot)

    if selected_ids_for_plot.size == 0:
        vlog("No valid sample_idx found or specified to plot. Returning.",
             level=2, verbose=verbose)
        return

    vlog(f"  Plotting for sample_idx: {selected_ids_for_plot.tolist()}",
         level=4, verbose=verbose)

    # --- Plotting Logic ---
    if kind == "temporal":
        num_main_plots = len(selected_ids_for_plot) * output_dim
        if num_main_plots == 0:
            vlog("No data to plot for temporal kind.", level=2, verbose=verbose)
            return

        n_cols_fig = min(max_cols, num_main_plots)
        n_rows_fig = (num_main_plots + n_cols_fig - 1) // n_cols_fig

        fig, axes = plt.subplots(
            n_rows_fig, n_cols_fig,
            figsize=(n_cols_fig * figsize_per_subplot[0],
                     n_rows_fig * figsize_per_subplot[1]),
            squeeze=False # Ensure axes is always 2D array
        )
        axes_flat = axes.flatten()
        current_plot_idx = 0

        for s_idx_val in selected_ids_for_plot:
            sample_df_to_plot = df_to_plot[df_to_plot['sample_idx'] == s_idx_val]
            if sample_df_to_plot.empty:
                continue

            for o_idx_val in range(output_dim):
                if current_plot_idx >= len(axes_flat): break
                ax = axes_flat[current_plot_idx]

                # Construct title
                plot_title = f"Sample ID: {s_idx_val}"
                if output_dim > 1:
                    plot_title += f", Target Dim: {o_idx_val}"
                if titles and current_plot_idx < len(titles):
                    plot_title = titles[current_plot_idx]
                ax.set_title(plot_title)

                # Plot actuals
                actual_col_name = base_actual_name
                if output_dim > 1: actual_col_name += f"_{o_idx_val}"
                actual_col_name += "_actual"
                if actual_col_name in sample_df_to_plot.columns:
                    ax.plot(
                        sample_df_to_plot['forecast_step'],
                        sample_df_to_plot[actual_col_name],
                        label='Actual', marker='o', linestyle='--'
                    )

                # Plot predictions (point or quantile)
                if sorted_quantiles_list:
                    # Determine median, lower, upper quantile columns
                    median_q = 0.5
                    if 0.5 not in sorted_quantiles_list: # Find closest
                        median_q = sorted_quantiles_list[
                            len(sorted_quantiles_list) // 2
                            ]
                    
                    col_prefix = base_pred_name
                    if output_dim > 1: col_prefix += f"_{o_idx_val}"
                    
                    median_col = f"{col_prefix}_q{int(median_q*100)}"
                    lower_col = f"{col_prefix}_q{int(sorted_quantiles_list[0]*100)}"
                    upper_col = f"{col_prefix}_q{int(sorted_quantiles_list[-1]*100)}"

                    if median_col in sample_df_to_plot.columns:
                        ax.plot(
                            sample_df_to_plot['forecast_step'],
                            sample_df_to_plot[median_col],
                            label=f'Median (q{int(median_q*100)})',
                            marker='x',
                            **plot_kwargs.get("median_plot_kwargs", {})
                        )
                    if lower_col in sample_df_to_plot.columns and \
                       upper_col in sample_df_to_plot.columns:
                        ax.fill_between(
                            sample_df_to_plot['forecast_step'],
                            sample_df_to_plot[lower_col],
                            sample_df_to_plot[upper_col],
                            color='gray', alpha=0.3,
                            label=f'Interval (q{int(sorted_quantiles_list[0]*100)}'
                                  f'-q{int(sorted_quantiles_list[-1]*100)})',
                            **plot_kwargs.get("fill_between_kwargs", {})
                        )
                else: # Point forecast
                    pred_col_name = base_pred_name
                    if output_dim > 1: pred_col_name += f"_{o_idx_val}"
                    pred_col_name += "_pred"
                    if pred_col_name in sample_df_to_plot.columns:
                        ax.plot(
                            sample_df_to_plot['forecast_step'],
                            sample_df_to_plot[pred_col_name],
                            label='Predicted', marker='x',
                            **plot_kwargs.get("point_plot_kwargs", {})
                        )
                ax.set_xlabel("Forecast Step into Horizon")
                ax.set_ylabel(
                    f"{target_name}{f' (Dim {o_idx_val})' if output_dim > 1 else ''}"
                    )
                ax.legend()
                ax.grid(True)
                current_plot_idx += 1

        # Hide any unused subplots
        for i in range(current_plot_idx, len(axes_flat)):
            axes_flat[i].set_visible(False)
        fig.tight_layout()
        plt.show()

    elif kind == "spatial":
        # ... (Spatial plotting logic as in previous artifact
        #      `visualize_forecasts_util`, ensuring it uses
        #      `sorted_quantiles_list` and correct column naming) ...
        if spatial_cols is None or len(spatial_cols) != 2:
            raise ValueError(
                "`spatial_cols` must be a list of two column names "
                "(e.g., ['longitude', 'latitude']) for kind='spatial'."
            )
        spatial_x_col, spatial_y_col = spatial_cols[0], spatial_cols[1]

        if spatial_x_col not in df_to_plot.columns or \
           spatial_y_col not in df_to_plot.columns:
            raise ValueError(
                f"Spatial columns '{spatial_x_col}' or '{spatial_y_col}' "
                "not found in forecast_df."
            )

        steps_to_plot_spatial: List[int] = []
        if isinstance(horizon_steps, int):
            steps_to_plot_spatial = [horizon_steps]
        elif isinstance(horizon_steps, list):
            steps_to_plot_spatial = horizon_steps
        elif horizon_steps is None or \
             str(horizon_steps).lower() == "all":
            steps_to_plot_spatial = sorted(df_to_plot['forecast_step'].unique())
        else:
            raise ValueError(f"Invalid `horizon_steps`: {horizon_steps}")
        
        num_main_plots = len(steps_to_plot_spatial) * output_dim
        if num_main_plots == 0:
            vlog("No data/steps to plot for spatial kind.", level=2, verbose=verbose)
            return

        n_cols_fig = min(max_cols, num_main_plots)
        n_rows_fig = (num_main_plots + n_cols_fig - 1) // n_cols_fig
        fig, axes = plt.subplots(
            n_rows_fig, n_cols_fig,
            figsize=(n_cols_fig * figsize_per_subplot[0],
                     n_rows_fig * figsize_per_subplot[1]),
            squeeze=False
        )
        axes_flat = axes.flatten()
        current_plot_idx = 0

        for step_val in steps_to_plot_spatial:
            step_df_to_plot = df_to_plot[df_to_plot['forecast_step'] == step_val]
            if step_df_to_plot.empty: continue

            for o_idx_val in range(output_dim):
                if current_plot_idx >= len(axes_flat): break
                ax = axes_flat[current_plot_idx]

                color_col_name, title_suffix = "", ""
                if sorted_quantiles_list:
                    median_q = 0.5
                    if 0.5 not in sorted_quantiles_list:
                        median_q = sorted_quantiles_list[len(sorted_quantiles_list)//2]
                    col_prefix = base_pred_name
                    if output_dim > 1: col_prefix += f"_{o_idx_val}"
                    color_col_name = f"{col_prefix}_q{int(median_q*100)}"
                    title_suffix = f" (Median q{int(median_q*100)})"
                else: # Point
                    color_col_name = base_pred_name
                    if output_dim > 1: color_col_name += f"_{o_idx_val}"
                    color_col_name += "_pred"

                if color_col_name not in step_df_to_plot.columns:
                    warnings.warn(f"Color column '{color_col_name}' not found "
                                  "for spatial plot. Skipping subplot.")
                    current_plot_idx +=1; continue
                
                scatter_data = step_df_to_plot.dropna(
                    subset=[spatial_x_col, spatial_y_col, color_col_name]
                    )
                if scatter_data.empty:
                    warnings.warn(f"No valid data for spatial plot (step "
                                  f"{step_val}, out_dim {o_idx_val}). Skipping.")
                    current_plot_idx += 1; continue

                norm = mcolors.Normalize(
                    vmin=scatter_data[color_col_name].min(),
                    vmax=scatter_data[color_col_name].max()
                    )
                cmap_val = plot_kwargs.get('cmap', 'viridis')
                sc = ax.scatter(
                    scatter_data[spatial_x_col], scatter_data[spatial_y_col],
                    c=scatter_data[color_col_name], cmap=cmap_val, norm=norm,
                    s=plot_kwargs.get('s', 50), alpha=plot_kwargs.get('alpha', 0.7)
                )
                fig.colorbar(sc, ax=ax, label=f"{target_name}{title_suffix}")
                plot_title = f"Forecast Step: {step_val}"
                if output_dim > 1: plot_title += f", Target Dim: {o_idx_val}"
                ax.set_title(plot_title)
                ax.set_xlabel(spatial_x_col); ax.set_ylabel(spatial_y_col)
                ax.grid(True); current_plot_idx += 1
        
        for i in range(current_plot_idx, len(axes_flat)):
            axes_flat[i].set_visible(False)
        fig.tight_layout()
        plt.show()
    else:
        raise ValueError(
            f"Unsupported `kind`: '{kind}'. Choose 'temporal' or 'spatial'."
            )
    vlog("Forecast visualization complete.", level=3, verbose=verbose)

    return ax

@isdf 
def plot_metric_over_horizon(
    forecast_df: pd.DataFrame,
    target_name: str = "target",
    metrics: Union[str, List[Union[str, Callable]]] = 'mae',
    quantiles: Optional[List[float]] = None,
    output_dim: int = 1,
    actual_col_pattern: str = "{target_name}_actual",
    pred_col_pattern_point: str = "{target_name}_pred",
    pred_col_pattern_quantile: str = "{target_name}_q{quantile_int}",
    group_by_cols: Optional[List[str]] = None,
    plot_kind: str = 'bar',
    figsize: Tuple[float, float] = (8, 5),
    max_cols_metrics: int = 2,
    scaler: Optional[Any] = None,
    scaler_feature_names: Optional[List[str]] = None,
    target_idx_in_scaler: Optional[int] = None,
    sharey_metrics: bool = False,
    verbose: int = 0,
    **plot_kwargs: Any
    ) -> None:
    """
    Visualizes specified performance metrics across the forecast horizon.
    
    This function takes a forecast DataFrame (typically from
    `format_predictions_to_dataframe`), calculates one or more
    performance metrics for each step in the forecast horizon,
    and plots these metrics. It supports point and quantile
    forecasts, multi-output dimensions, and optional grouping by
    other columns (e.g., item ID, region).
    
    Parameters
    ----------
    forecast_df : pd.DataFrame
        A pandas DataFrame containing the forecast data in long format.
        Must include 'sample_idx', 'forecast_step', prediction columns,
        and actual value columns (e.g., '{target_name}_actual').
    target_name : str, default "target"
        The base name of the target variable. Used to find relevant
        prediction and actual columns.
    metrics : str or List[Union[str, Callable]], default 'mae'
        Metric(s) to calculate and plot.
        - Supported string names: 'mae', 'mse', 'rmse', 'mape',
          'smape', 'coverage' (requires `quantiles`),
          'pinball_median' (requires `quantiles` with 0.5).
        - Custom metric: A callable that accepts `(y_true, y_pred)`
          and returns a scalar score. If `quantiles` are used and
          metric is custom, `y_pred` will be the median prediction.
    quantiles : List[float], optional
        List of quantiles predicted, e.g., `[0.1, 0.5, 0.9]`. Required
        if 'coverage' or 'pinball_median' metrics are used.
        Default is ``None``.
    output_dim : int, default 1
        Number of target variables (output dimensions) predicted.
        If > 1, plots for each dimension are generated or overlaid.
    actual_col_pattern : str, default "{target_name}_actual"
        Format string to identify actual value columns.
        Example: "{target_name}_{output_idx}_actual" for multi-output.
    pred_col_pattern_point : str, default "{target_name}_pred"
        Format string for point prediction columns.
        Example: "{target_name}_{output_idx}_pred" for multi-output.
    pred_col_pattern_quantile : str, default "{target_name}_q{quantile_int}"
        Format string for quantile prediction columns.
        Placeholders: `{target_name}`, `{output_idx}`, `{quantile_int}`.
        Example: "{target_name}_{output_idx}_q{quantile_int}".
    group_by_cols : List[str], optional
        Column(s) in `forecast_df` to group by before calculating
        metrics. Metrics will be plotted as separate lines/bar groups
        for each segment. Default is ``None`` (global metrics).
    plot_kind : {'bar', 'line'}, default 'bar'
        Type of plot to generate for the metrics over the horizon.
    figsize_per_metric : Tuple[float, float], default (8, 5)
        Figure size `(width, height)` for each individual metric's plot
        if multiple metrics are plotted in separate subplots.
    max_cols_metrics : int, default 2
        Maximum number of metric subplots per row if multiple metrics
        are specified.
    scaler : Any, optional
        Fitted scikit-learn-like scaler for inverse transforming data
        before metric calculation. Default is ``None`` (metrics on
        scaled data).
    scaler_feature_names : List[str], optional
        List of all feature names (in order) the `scaler` was fit on.
        Required if `scaler` is provided.
    target_idx_in_scaler : int, optional
        Index of `target_name` within `scaler_feature_names`.
        Required if `scaler` is provided.
    sharey_metrics : bool, default False
        If True and multiple metrics are plotted as subplots, they
        will share the same y-axis limits (if appropriate).
    verbose : int, default 0
        Verbosity level for logging.
        - ``0``: Silent.
        - ``1`` or higher: Print informational messages.
    **plot_kwargs : Any
        Additional keyword arguments passed to the underlying
        Matplotlib plotting functions (`ax.bar()`, `ax.plot()`).
    
    Returns
    -------
    None
        This function generates and shows plots using Matplotlib.
    
    Raises
    ------
    ValueError
        If `forecast_df` is missing required columns.
        If `metrics` contains unsupported string names or invalid callables.
        If `quantiles` are required for a metric but not provided.
    TypeError
        If `forecast_df` is not a pandas DataFrame.
    
    See Also
    --------
    fusionlab.nn.utils.format_predictions_to_dataframe :
        Utility to generate the `forecast_df`.
    fusionlab.metrics : Module containing metric implementations.
    
    Examples
    --------
    >>> from fusionlab.nn.utils import format_predictions_to_dataframe, plot_metric_over_horizon
    >>> import pandas as pd
    >>> import numpy as np
    
    >>> # Assume preds_quant (B,H,Q) and y_true_seq (B,H,O) are available
    >>> B, H, O, Q_list = 4, 3, 1, [0.1, 0.5, 0.9]
    >>> preds_q = np.random.rand(B, H, len(Q_list))
    >>> y_true = np.random.rand(B, H, O) + preds_q[:,:,1:2]*0.5 # Actuals near median
    >>> df_q = format_predictions_to_dataframe(
    ...     predictions=preds_q, y_true_sequences=y_true,
    ...     target_name="demand", quantiles=Q_list,
    ...     forecast_horizon=H, output_dim=O
    ... )
    >>> df_q['item_id'] = np.repeat(['itemA', 'itemB'], H * B / 2) # Add a segment column
    
    >>> # Example 1: Plot MAE of median forecast over horizon
    >>> # plot_metric_over_horizon(df_q, target_name="demand",
    ... #                        metrics='mae', quantiles=Q_list, # MAE on median
    ... #                        plot_kind='line')
    
    >>> # Example 2: Plot Coverage and MAE, grouped by item_id
    >>> # plot_metric_over_horizon(df_q, target_name="demand",
    ... #                        metrics=['coverage', 'mae'],
    ... #                        quantiles=Q_list,
    ... #                        group_by_cols=['item_id'],
    ... #                        max_cols_metrics=1)
    """

    vlog(f"Starting metric visualization over horizon "
         f"(kind='{plot_kind}')...", level=3, verbose=verbose)

    if not isinstance(forecast_df, pd.DataFrame):
        raise TypeError("`forecast_df` must be a pandas DataFrame.")
  
    if 'forecast_step' not in forecast_df.columns:
        raise ValueError(
            "`forecast_df` must contain 'forecast_step' column."
            )

    df_to_eval = forecast_df.copy()

    # --- Inverse Transform Data if Scaler Provided ---
    if scaler is not None:
        if scaler_feature_names is None or target_idx_in_scaler is None:
            warnings.warn(
                "Scaler provided, but `scaler_feature_names` or "
                "`target_idx_in_scaler` is missing. Cannot perform "
                "targeted inverse transform. Metrics calculated on "
                "scaled data.", UserWarning
            )
        else:
            vlog("  Applying inverse transformation for metric calculation...",
                 level=4, verbose=verbose)
            # Identify all potential prediction and actual columns to inverse
            cols_to_inverse = []
            for o_idx in range(output_dim):
                act_col = actual_col_pattern.format(
                    target_name=target_name, o_idx=o_idx)
                if act_col in df_to_eval.columns:
                    cols_to_inverse.append(act_col)

                if quantiles:
                    for q_val in quantiles:
                        q_int = int(q_val * 100)
                        pred_col = pred_col_pattern_quantile.format(
                            target_name=target_name, o_idx=o_idx,
                            quantile_int=q_int
                        )
                        if pred_col in df_to_eval.columns:
                            cols_to_inverse.append(pred_col)
                else: # Point
                    pred_col = pred_col_pattern_point.format(
                        target_name=target_name, o_idx=o_idx
                    )
                    if pred_col in df_to_eval.columns:
                        cols_to_inverse.append(pred_col)
            
            dummy_array_shape = (len(df_to_eval), len(scaler_feature_names))
            for col_name in cols_to_inverse:
                if col_name in df_to_eval.columns:
                    try:
                        dummy = np.zeros(dummy_array_shape)
                        dummy[:, target_idx_in_scaler] = df_to_eval[col_name]
                        df_to_eval[col_name] = scaler.inverse_transform(
                            dummy
                            )[:, target_idx_in_scaler]
                    except Exception as e:
                        warnings.warn(
                            f"Failed to inverse transform column '{col_name}'. "
                            f"Metric may be on scaled value. Error: {e}"
                            )
            vlog("    Inverse transformation applied.", level=5, verbose=verbose)

    # --- Prepare Metrics ---
    if isinstance(metrics, str):
        metrics_list = [metrics]
    elif isinstance(metrics, list):
        metrics_list = metrics
    else:
        raise TypeError("`metrics` must be a string or a list.")

    metric_results = [] # Store (metric_name, output_dim_idx, group, step, value)

    # --- Calculate Metrics ---
    for o_idx in range(output_dim): # Loop through each output dimension
        # Construct actual column name for this output dimension
        actual_col = actual_col_pattern.format(
            target_name=target_name, o_idx=o_idx
            )
        if actual_col not in df_to_eval.columns:
            warnings.warn(
                f"Actual column '{actual_col}' not found. Skipping metrics "
                f"for output dimension {o_idx}.", UserWarning
            )
            continue

        # y_true_series = df_to_eval[actual_col]

        for metric_func_or_name in metrics_list:
            metric_name = ""
            current_metric_callable = None

            if isinstance(metric_func_or_name, str):
                metric_name = metric_func_or_name.lower()
                if metric_name == 'mae':
                    current_metric_callable = mean_absolute_error
                elif metric_name == 'mse':
                    current_metric_callable = mean_squared_error
                elif metric_name == 'rmse':
                    current_metric_callable = lambda yt, yp: np.sqrt(
                        mean_squared_error(yt, yp))
                elif metric_name == 'mape':
                    current_metric_callable = mean_absolute_percentage_error
                elif metric_name == 'smape':
                    current_metric_callable = _calculate_smape
                elif metric_name == 'coverage':
                    if not quantiles or len(quantiles) < 2:
                        warnings.warn("Coverage metric requires at least two "
                                      "quantiles. Skipping.", UserWarning)
                        continue
                 
                    # Coverage needs lower and upper quantile predictions
                    q_low_col = pred_col_pattern_quantile.format(
                        target_name=target_name, o_idx=o_idx,
                        quantile_int=int(sorted(quantiles)[0]*100)
                    )
                    q_high_col = pred_col_pattern_quantile.format(
                        target_name=target_name, o_idx=o_idx,
                        quantile_int=int(sorted(quantiles)[-1]*100)
                    )
                    if q_low_col not in df_to_eval.columns or \
                       q_high_col not in df_to_eval.columns:
                        warnings.warn(f"Quantile columns for coverage "
                                      f"({q_low_col}, {q_high_col}) not found. "
                                      "Skipping coverage.", UserWarning)
                        continue
                    # Wrapper for coverage_score
                    current_metric_callable = lambda yt, yp_dict: \
                        coverage_score(
                            yt, yp_dict[q_low_col], yp_dict[q_high_col]
                            )
                elif metric_name == 'pinball_median':
                    if not quantiles or 0.5 not in quantiles:
                        warnings.warn("Pinball_median metric requires 0.5 "
                                      "in quantiles. Skipping.", UserWarning)
                        continue
                    q_median_col = pred_col_pattern_quantile.format(
                        target_name=target_name, o_idx=o_idx, quantile_int=50
                        )
                    if q_median_col not in df_to_eval.columns:
                        warnings.warn(f"Median quantile column '{q_median_col}' "
                                      "not found. Skipping pinball_median.", UserWarning)
                        continue
                    current_metric_callable = lambda yt, yp_dict: \
                        _calculate_pinball_loss(yt, yp_dict[q_median_col], 0.5)
                else:
                    warnings.warn(f"Unknown metric string: '{metric_name}'. "
                                  "Skipping.", UserWarning)
                    continue
            elif callable(metric_func_or_name):
                current_metric_callable = metric_func_or_name
                metric_name = getattr(metric_func_or_name, '__name__', 'custom_metric')
            else:
                warnings.warn(f"Invalid metric type: {type(metric_func_or_name)}. "
                              "Skipping.", UserWarning)
                continue

            # Determine prediction column(s) for this metric
            y_pred_for_metric_source = None # Can be a Series or DataFrame for coverage
            if metric_name == 'coverage':
                # Pass a dictionary of relevant quantile columns to the wrapper
                y_pred_for_metric_source = df_to_eval[[q_low_col, q_high_col]]
            elif metric_name == 'pinball_median':
                y_pred_for_metric_source = df_to_eval[[q_median_col]]
            elif quantiles: # For MAE, MSE etc. on quantile forecasts, use median
                median_q = 0.5
                if 0.5 not in quantiles:
                    median_q = sorted(quantiles)[len(quantiles) // 2]
                    warnings.warn(f"0.5 quantile not found for metric '{metric_name}'. "
                                  f"Using q={median_q} instead.", UserWarning)
                pred_col = pred_col_pattern_quantile.format(
                    target_name=target_name, o_idx=o_idx,
                    quantile_int=int(median_q*100)
                )
                if pred_col in df_to_eval.columns:
                    y_pred_for_metric_source = df_to_eval[pred_col]
                else:
                    warnings.warn(f"Median prediction column '{pred_col}' "
                                  f"not found for metric '{metric_name}'. Skipping.",
                                  UserWarning)
                    continue
            else: # Point forecast
                pred_col = pred_col_pattern_point.format(
                    target_name=target_name, o_idx=o_idx
                )
                if pred_col in df_to_eval.columns:
                    y_pred_for_metric_source = df_to_eval[pred_col]
                else:
                    warnings.warn(f"Point prediction column '{pred_col}' "
                                  f"not found for metric '{metric_name}'. Skipping.",
                                  UserWarning)
                    continue
            
            # Group data and calculate metric per step
            grouped_data = df_to_eval.groupby(
                group_by_cols + ['forecast_step'] if group_by_cols else ['forecast_step']
                )

            for group_keys, group_df in grouped_data:
                if not isinstance(group_keys, tuple): # Ensure group_keys is a tuple
                    group_keys = (group_keys,)
                
                step = group_keys[-1] # Last key is 'forecast_step'
                group_id = "_".join(map(str, group_keys[:-1])) if group_by_cols else "overall"

                y_true_step = group_df[actual_col]
                if metric_name in ['coverage', 'pinball_median']:
                    # Pass the relevant DataFrame slice for these metrics
                    y_pred_step = y_pred_for_metric_source.loc[group_df.index]
                else:
                    y_pred_step = y_pred_for_metric_source.loc[group_df.index]

                if len(y_true_step) == 0 or len(y_pred_step) == 0:
                    continue # Skip if no data for this step/group

                try:
                    metric_value = current_metric_callable(y_true_step, y_pred_step)
                    metric_results.append({
                        'metric': metric_name,
                        'output_dim': o_idx,
                        'group': group_id,
                        'forecast_step': step,
                        'value': metric_value
                    })
                except Exception as e:
                    warnings.warn(f"Error calculating metric '{metric_name}' "
                                  f"for group '{group_id}', step {step}, "
                                  f"output_dim {o_idx}: {e}", UserWarning)

    if not metric_results:
        vlog("No metric results to plot.", level=2, verbose=verbose)
        return

    results_df = pd.DataFrame(metric_results)

    # --- Plotting --
    
    # num_metrics_to_plot = results_df['metric'].nunique()
    # num_output_dims_to_plot = results_df['output_dim'].nunique()

    # If multiple output_dims, create one figure per output_dim,
    # with subplots for each metric.
    # Or, one figure per metric, with lines for each output_dim.
    # For simplicity, let's do one figure per output_dim if output_dim > 1.
    
    output_dims_present = sorted(results_df['output_dim'].unique())

    for o_idx_plot in output_dims_present:
        df_plot_dim = results_df[results_df['output_dim'] == o_idx_plot]
        if df_plot_dim.empty:
            continue

        metrics_for_this_dim = sorted(df_plot_dim['metric'].unique())
        n_met_plots = len(metrics_for_this_dim)
        if n_met_plots == 0: continue

        n_cols_fig = min(max_cols_metrics, n_met_plots)
        n_rows_fig = (n_met_plots + n_cols_fig - 1) // n_cols_fig

        fig, axes = plt.subplots(
            n_rows_fig, n_cols_fig,
            figsize=(n_cols_fig * figsize[0],
                     n_rows_fig * figsize[1]),
            squeeze=False, sharey=sharey_metrics
        )
        axes_flat = axes.flatten()
        current_plot_idx = 0

        fig_title = "Metrics Over Horizon"
        if output_dim > 1:
            fig_title += f" (Output Dimension {o_idx_plot})"
        fig.suptitle(fig_title, fontsize=16)

        for metric_name_plot in metrics_for_this_dim:
            if current_plot_idx >= len(axes_flat): break
            ax = axes_flat[current_plot_idx]
            metric_df = df_plot_dim[df_plot_dim['metric'] == metric_name_plot]

            if group_by_cols:
                for group_val, group_data in metric_df.groupby('group'):
                    group_data = group_data.sort_values('forecast_step')
                    if plot_kind == 'bar':
                        # Bar plot needs careful positioning for groups
                        # For simplicity, use line for grouped bar for now
                        ax.plot(group_data['forecast_step'], group_data['value'],
                                label=f"{group_val}", marker='o',
                                **plot_kwargs.get(f"{metric_name_plot}_plot_kwargs", {}))
                    else: # line
                        ax.plot(group_data['forecast_step'], group_data['value'],
                                label=f"{group_val}", marker='o',
                                **plot_kwargs.get(f"{metric_name_plot}_plot_kwargs", {}))
                ax.legend(title=str(group_by_cols))
            else: # No grouping
                metric_df = metric_df.sort_values('forecast_step')
                if plot_kind == 'bar':
                    ax.bar(metric_df['forecast_step'], metric_df['value'],
                           **plot_kwargs.get(f"{metric_name_plot}_plot_kwargs", {}))
                else: # line
                    ax.plot(metric_df['forecast_step'], metric_df['value'],
                            marker='o',
                            **plot_kwargs.get(f"{metric_name_plot}_plot_kwargs", {}))

            ax.set_title(f"{metric_name_plot.upper()}")
            ax.set_xlabel("Forecast Step")
            ax.set_ylabel("Metric Value")
            ax.grid(True, linestyle='--', alpha=0.7)
            current_plot_idx += 1

        # Hide unused subplots
        for i in range(current_plot_idx, len(axes_flat)):
            axes_flat[i].set_visible(False)

        fig.tight_layout(rect=[0, 0, 1, 0.96]) # Adjust for suptitle
        plt.show()

    vlog("Metric visualization over horizon complete.",
         level=3, verbose=verbose)


def _calculate_pinball_loss(
    y_true: np.ndarray,
    y_pred_q50: np.ndarray,
    quantile: float = 0.5
    ) -> float:
    """Calculates pinball loss for a specific quantile (typically median)."""
    err = y_true - y_pred_q50
    return np.mean(np.maximum(quantile * err, (quantile - 1) * err))

def _calculate_smape(y_true: np.ndarray, y_pred: np.ndarray) -> float:
    """Calculates Symmetric Mean Absolute Percentage Error (SMAPE)."""
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2
    # Handle division by zero if both true and pred are zero
    denominator[denominator == 0] = 1e-9 # Avoid division by zero
    return np.mean(numerator / denominator) * 100


def _calculate_pinball_loss_radar(
    y_true: np.ndarray,
    y_pred_q50: np.ndarray,
    quantile: float = 0.5 # Default to median for pinball
    ) -> float:
    """Calculates pinball loss for a specific quantile."""
    err = y_true - y_pred_q50
    return np.mean(np.maximum(quantile * err, (quantile - 1) * err))

def _calculate_smape_radar(
    y_true: np.ndarray, y_pred: np.ndarray
    ) -> float:
    """Calculates Symmetric Mean Absolute Percentage Error (SMAPE)."""
    numerator = np.abs(y_pred - y_true)
    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2.0
    # Handle division by zero if both true and pred are zero
    # Add a small epsilon to denominator where it's zero
    epsilon = 1e-9
    score = np.mean(
        numerator / (denominator + epsilon)
        ) * 100
    return score